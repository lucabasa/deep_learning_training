{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a48194f-61c6-44a0-b177-335a93ae4a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "#%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce5fb1ac-7908-4a6a-8db5-aee535ea0c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pythonprogramming.net/building-deep-learning-neural-network-pytorch/?completed=/data-deep-learning-neural-network-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd581418-c226-4c7f-a116-fc9349a516cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(root='data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "test = datasets.MNIST(root='data', train=False, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0533a07d-a495-4dfd-aa2c-97e658c07d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # it will expect a flatten tensor \n",
    "        self.fc1 = nn.Linear(28*28, 64)  # 28x28 is the image size\n",
    "        self.fc2 = nn.Linear(64, 64)  # 64 is the size of the previous layer\n",
    "        self.fc3 = nn.Linear(64, 64)  # the size is arbitrary at this stage\n",
    "        self.fc4 = nn.Linear(64, 10)  # 10 are the labels at the end\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)  # to get a prob distribution\n",
    "\n",
    "net = Net()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d30b8b99-5bb2-4b7f-ab80-5e83ab3ab5e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (28x28 and 784x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn((\u001b[38;5;241m28\u001b[39m,\u001b[38;5;241m28\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# should break\u001b[39;00m\n",
      "File \u001b[0;32m~/Git/deep_learning_training/dl_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[4], line 12\u001b[0m, in \u001b[0;36mNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 12\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     13\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n\u001b[1;32m     14\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(x))\n",
      "File \u001b[0;32m~/Git/deep_learning_training/dl_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Git/deep_learning_training/dl_env/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (28x28 and 784x64)"
     ]
    }
   ],
   "source": [
    "X = torch.randn((28,28))\n",
    "output = net(X)  # should break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "125f425b-47ab-4c53-aa97-53b7b9689032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1759, -2.3039, -2.3336, -2.1967, -2.4114, -2.3125, -2.4262, -2.1927,\n",
       "         -2.3041, -2.4082]], grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.view(-1,28*28)  # -1 for 'any size', it can be the batch size\n",
    "output = net(X)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f290cd8d-d56d-4a29-acc2-dc33e34e96b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62710967-da36-484f-a5ae-20b1dad4bf51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db19bd9d-df95-4c81-a1d5-b09284ca6df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3549, -2.2973, -2.3206, -2.2746, -2.1795, -2.4320, -2.3186, -2.2131,\n",
       "         -2.3336, -2.3244]], device='cuda:0', grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(28, 28, device=device).view(-1,28*28)\n",
    "logits = model(X)\n",
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8807c1f5-ba99-43ca-b827-2a955fedfc02",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "133c7274-3038-42c6-a620-e3b5449635e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1950, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0478, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0056, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1298, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0537, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.5707e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=0.001)  # parameters is everything adjustable, in transfer learning for example not everything is adjustable\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS): # 3 full passes over the data\n",
    "    for X, y in trainset:  # `data` is a batch of data\n",
    "        # X is the batch of features, y is the batch of targets.\n",
    "        net.zero_grad()  # sets gradients to 0 before loss calc. You will do this likely every step.\n",
    "        \n",
    "        output = net(X.view(-1, 28*28))  # pass in the reshaped batch (recall they are 28x28 atm)\n",
    "        \n",
    "        loss = F.nll_loss(output, y)  # calc and grab the loss value, negative log likelihood\n",
    "        \n",
    "        loss.backward()  # apply this loss backwards thru the network's parameters\n",
    "        optimizer.step()  # attempt to optimize weights to account for loss/gradients\n",
    "        \n",
    "    print(loss)  # print loss. We hope loss (a measure of wrong-ness) declines!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dcfa5e4-dee5-4469-87ff-2a3d7a738ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.975\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1,784))\n",
    "        #print(output)\n",
    "        for idx, i in enumerate(output):\n",
    "            #print(torch.argmax(i), y[idx])\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea65ab8f-b82e-44a3-94b5-82c3453c7b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X[0].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8126763d-4a09-4c8e-93d7-259b8f373abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(net(X[0].view(-1,784))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f306c7b-8fbc-4d3f-891d-d862289e6ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
